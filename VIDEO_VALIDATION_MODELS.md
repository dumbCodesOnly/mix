# Video Validation Models\n\nThis document defines the Pydantic validation models for video generation requests and responses.\n\n## Request Models\n\n### TextToVideoRequest\n\nValidation model for text-to-video generation requests.\n\n```python\nfrom pydantic import BaseModel, Field\nfrom typing import Optional\n\nclass TextToVideoRequest(BaseModel):\n    \"\"\"\n    Request model for text-to-video generation.\n    \n    Attributes:\n        prompt: Text description of the video to generate\n        model: HuggingFace model ID (optional, uses default if not specified)\n        negative_prompt: What to avoid in the generated video\n        duration: Video duration in seconds (1-30)\n        fps: Frames per second (1-60)\n        num_inference_steps: Quality/speed tradeoff (1-100)\n    \"\"\"\n    prompt: str = Field(\n        ...,\n        min_length=1,\n        max_length=1000,\n        description=\"Text description of the video\"\n    )\n    model: Optional[str] = Field(\n        None,\n        description=\"HuggingFace model ID\"\n    )\n    negative_prompt: Optional[str] = Field(\n        None,\n        max_length=500,\n        description=\"What to avoid in the video\"\n    )\n    duration: int = Field(\n        default=6,\n        ge=1,\n        le=30,\n        description=\"Video duration in seconds\"\n    )\n    fps: int = Field(\n        default=8,\n        ge=1,\n        le=60,\n        description=\"Frames per second\"\n    )\n    num_inference_steps: int = Field(\n        default=50,\n        ge=1,\n        le=100,\n        description=\"Inference steps for quality\"\n    )\n\n    class Config:\n        json_schema_extra = {\n            \"example\": {\n                \"prompt\": \"A cat walking through a garden\",\n                \"duration\": 8,\n                \"fps\": 24,\n                \"num_inference_steps\": 50\n            }\n        }\n```\n\n### ImageToVideoRequest\n\nValidation model for image-to-video generation requests.\n\n```python\nclass ImageToVideoRequest(BaseModel):\n    \"\"\"\n    Request model for image-to-video generation.\n    \n    Attributes:\n        image: Base64 encoded image data\n        model: HuggingFace model ID (optional)\n        prompt: Optional text prompt for video style\n        duration: Video duration in seconds (1-30)\n        fps: Frames per second (1-60)\n        num_inference_steps: Quality/speed tradeoff (1-100)\n    \"\"\"\n    image: str = Field(\n        ...,\n        description=\"Base64 encoded image data\"\n    )\n    model: Optional[str] = Field(\n        None,\n        description=\"HuggingFace model ID\"\n    )\n    prompt: Optional[str] = Field(\n        None,\n        max_length=500,\n        description=\"Optional text prompt for video style\"\n    )\n    duration: int = Field(\n        default=6,\n        ge=1,\n        le=30,\n        description=\"Video duration in seconds\"\n    )\n    fps: int = Field(\n        default=8,\n        ge=1,\n        le=60,\n        description=\"Frames per second\"\n    )\n    num_inference_steps: int = Field(\n        default=50,\n        ge=1,\n        le=100,\n        description=\"Inference steps for quality\"\n    )\n\n    class Config:\n        json_schema_extra = {\n            \"example\": {\n                \"image\": \"base64_encoded_image_data\",\n                \"prompt\": \"cinematic camera movement\",\n                \"fps\": 24\n            }\n        }\n```\n\n## Response Models\n\n### VideoGenerationResponse\n\nValidation model for video generation responses.\n\n```python\nclass VideoGenerationResponse(BaseModel):\n    \"\"\"\n    Response model for video generation.\n    \n    Attributes:\n        video_url: URL to download the generated video\n        video_size: Size of the video file in bytes\n        duration: Actual video duration in seconds\n        fps: Actual frames per second\n        resolution: Video resolution (width x height)\n        model: Model used for generation\n        generation_time: Time taken to generate video in seconds\n        format: Video file format (mp4, webm, etc.)\n    \"\"\"\n    video_url: str = Field(\n        ...,\n        description=\"URL to download the video\"\n    )\n    video_size: int = Field(\n        ...,\n        description=\"Video file size in bytes\"\n    )\n    duration: float = Field(\n        ...,\n        description=\"Video duration in seconds\"\n    )\n    fps: int = Field(\n        ...,\n        description=\"Frames per second\"\n    )\n    resolution: str = Field(\n        ...,\n        description=\"Video resolution (e.g., '1024x576')\"\n    )\n    model: str = Field(\n        ...,\n        description=\"Model used for generation\"\n    )\n    generation_time: float = Field(\n        ...,\n        description=\"Time taken to generate in seconds\"\n    )\n    format: str = Field(\n        default=\"mp4\",\n        description=\"Video file format\"\n    )\n\n    class Config:\n        json_schema_extra = {\n            \"example\": {\n                \"video_url\": \"http://localhost:8000/videos/abc123.mp4\",\n                \"video_size\": 5242880,\n                \"duration\": 6.0,\n                \"fps\": 8,\n                \"resolution\": \"576x320\",\n                \"model\": \"damo-vilab/text-to-video-ms-1.7b\",\n                \"generation_time\": 45.2,\n                \"format\": \"mp4\"\n            }\n        }\n```\n\n### VideoMetadata\n\nValidation model for video metadata.\n\n```python\nclass VideoMetadata(BaseModel):\n    \"\"\"\n    Video metadata for caching and tracking.\n    \n    Attributes:\n        video_id: Unique identifier for the video\n        prompt: Original prompt used\n        model: Model used for generation\n        created_at: Timestamp of creation\n        duration: Video duration\n        resolution: Video resolution\n    \"\"\"\n    video_id: str = Field(\n        ...,\n        description=\"Unique video identifier\"\n    )\n    prompt: str = Field(\n        ...,\n        description=\"Original prompt\"\n    )\n    model: str = Field(\n        ...,\n        description=\"Model used\"\n    )\n    created_at: str = Field(\n        ...,\n        description=\"ISO 8601 timestamp\"\n    )\n    duration: float = Field(\n        ...,\n        description=\"Video duration in seconds\"\n    )\n    resolution: str = Field(\n        ...,\n        description=\"Video resolution\"\n    )\n```\n\n## Implementation in Code\n\n### Adding to validation.py\n\n```python\n# app/utils/validation.py\n\nfrom pydantic import BaseModel, Field\nfrom typing import Optional\nfrom datetime import datetime\n\n# Text-to-Video Models\nclass TextToVideoRequest(BaseModel):\n    prompt: str = Field(\n        ...,\n        min_length=1,\n        max_length=1000,\n        description=\"Text description of the video\"\n    )\n    model: Optional[str] = Field(\n        None,\n        description=\"HuggingFace model ID\"\n    )\n    negative_prompt: Optional[str] = Field(\n        None,\n        max_length=500,\n        description=\"What to avoid in the video\"\n    )\n    duration: int = Field(\n        default=6,\n        ge=1,\n        le=30,\n        description=\"Video duration in seconds\"\n    )\n    fps: int = Field(\n        default=8,\n        ge=1,\n        le=60,\n        description=\"Frames per second\"\n    )\n    num_inference_steps: int = Field(\n        default=50,\n        ge=1,\n        le=100,\n        description=\"Inference steps for quality\"\n    )\n\n# Image-to-Video Models\nclass ImageToVideoRequest(BaseModel):\n    image: str = Field(\n        ...,\n        description=\"Base64 encoded image data\"\n    )\n    model: Optional[str] = Field(\n        None,\n        description=\"HuggingFace model ID\"\n    )\n    prompt: Optional[str] = Field(\n        None,\n        max_length=500,\n        description=\"Optional text prompt for video style\"\n    )\n    duration: int = Field(\n        default=6,\n        ge=1,\n        le=30,\n        description=\"Video duration in seconds\"\n    )\n    fps: int = Field(\n        default=8,\n        ge=1,\n        le=60,\n        description=\"Frames per second\"\n    )\n    num_inference_steps: int = Field(\n        default=50,\n        ge=1,\n        le=100,\n        description=\"Inference steps for quality\"\n    )\n\n# Video Response Models\nclass VideoGenerationResponse(BaseModel):\n    video_url: str = Field(\n        ...,\n        description=\"URL to download the video\"\n    )\n    video_size: int = Field(\n        ...,\n        description=\"Video file size in bytes\"\n    )\n    duration: float = Field(\n        ...,\n        description=\"Video duration in seconds\"\n    )\n    fps: int = Field(\n        ...,\n        description=\"Frames per second\"\n    )\n    resolution: str = Field(\n        ...,\n        description=\"Video resolution\"\n    )\n    model: str = Field(\n        ...,\n        description=\"Model used for generation\"\n    )\n    generation_time: float = Field(\n        ...,\n        description=\"Time taken to generate in seconds\"\n    )\n    format: str = Field(\n        default=\"mp4\",\n        description=\"Video file format\"\n    )\n\nclass VideoMetadata(BaseModel):\n    video_id: str\n    prompt: str\n    model: str\n    created_at: str\n    duration: float\n    resolution: str\n```\n\n## Validation Rules\n\n### Text-to-Video Validation\n\n1. **Prompt**: 1-1000 characters, required\n2. **Duration**: 1-30 seconds, default 6\n3. **FPS**: 1-60 frames per second, default 8\n4. **Inference Steps**: 1-100, default 50\n5. **Model**: Optional, uses default if not specified\n\n### Image-to-Video Validation\n\n1. **Image**: Base64 encoded, required\n2. **Image Size**: Maximum 10MB\n3. **Image Format**: PNG, JPG, WebP\n4. **Duration**: 1-30 seconds, default 6\n5. **FPS**: 1-60 frames per second, default 8\n6. **Inference Steps**: 1-100, default 50\n\n## Error Handling\n\n### Validation Errors\n\n```python\nfrom fastapi import HTTPException\nfrom pydantic import ValidationError\n\ntry:\n    request = TextToVideoRequest(**request_data)\nexcept ValidationError as e:\n    raise HTTPException(\n        status_code=422,\n        detail={\n            \"error\": \"validation_error\",\n            \"message\": \"Invalid request parameters\",\n            \"details\": e.errors()\n        }\n    )\n```\n\n### Common Validation Errors\n\n| Error | Cause | Solution |\n|-------|-------|----------|\n| `prompt` required | Missing prompt field | Add prompt to request |\n| `duration` > 30 | Duration too long | Reduce to ≤ 30 seconds |\n| `fps` > 60 | FPS too high | Reduce to ≤ 60 fps |\n| `image` invalid | Invalid base64 | Encode image as base64 |\n| `image` too large | Image > 10MB | Use smaller image |\n\n## Usage Examples\n\n### Valid Text-to-Video Request\n\n```json\n{\n  \"prompt\": \"A beautiful sunset over mountains with birds flying\",\n  \"model\": \"damo-vilab/text-to-video-ms-1.7b\",\n  \"duration\": 8,\n  \"fps\": 24,\n  \"num_inference_steps\": 50\n}\n```\n\n### Valid Image-to-Video Request\n\n```json\n{\n  \"image\": \"iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNk+M9QDwADhgGAWjR9awAAAABJRU5ErkJggg==\",\n  \"prompt\": \"cinematic camera movement\",\n  \"fps\": 24,\n  \"duration\": 6\n}\n```\n\n### Invalid Requests\n\n```json\n// Missing required prompt\n{\n  \"duration\": 8\n}\n\n// Duration exceeds maximum\n{\n  \"prompt\": \"A cat\",\n  \"duration\": 60\n}\n\n// Invalid FPS\n{\n  \"prompt\": \"A cat\",\n  \"fps\": 120\n}\n```\n
